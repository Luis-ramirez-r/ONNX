{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "# import  random forest regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from joblib import dump, load\n",
    "import onnxmltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000 # número de filas\n",
    "n_features = 100 # número de columnas\n",
    "\n",
    "X, y = make_regression(n_samples=n_samples, n_features=n_features, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Entrenamiento de los modelos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model_lr \u001b[39m=\u001b[39m LinearRegression()\u001b[39m.\u001b[39mfit(X, y)\n\u001b[0;32m----> 5\u001b[0m model_xgb \u001b[39m=\u001b[39m RandomForestRegressor()\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Guardado de los modelos\u001b[39;00m\n\u001b[1;32m      8\u001b[0m dump(model_lr, \u001b[39m\"\u001b[39m\u001b[39mmodelos/model_lr.joblib\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    477\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    478\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    479\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    480\u001b[0m )(\n\u001b[1;32m    481\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    482\u001b[0m         t,\n\u001b[1;32m    483\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    484\u001b[0m         X,\n\u001b[1;32m    485\u001b[0m         y,\n\u001b[1;32m    486\u001b[0m         sample_weight,\n\u001b[1;32m    487\u001b[0m         i,\n\u001b[1;32m    488\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    489\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    490\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    491\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    492\u001b[0m     )\n\u001b[1;32m    493\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    494\u001b[0m )\n\u001b[1;32m    496\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    187\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 189\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    190\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/tree/_classes.py:1342\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1314\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \n\u001b[1;32m   1316\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1342\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   1343\u001b[0m         X,\n\u001b[1;32m   1344\u001b[0m         y,\n\u001b[1;32m   1345\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1346\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m   1347\u001b[0m     )\n\u001b[1;32m   1348\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples=n_samples, n_features=n_features, random_state=0)\n",
    "\n",
    "# Entrenamiento de los modelos\n",
    "model_lr = LinearRegression().fit(X, y)\n",
    "model_xgb = RandomForestRegressor().fit(X, y)\n",
    "\n",
    "# Guardado de los modelos\n",
    "dump(model_lr, \"modelos/model_lr.joblib\")\n",
    "dump(model_xgb, \"modelos/model_xgb.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X, columns=[\"feature_\" + str(i) for i in range(n_features)])\n",
    "df[\"target\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"data/data_regression.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instala onnx y onnx runtime\n",
    "#!pip install onnxruntime    \n",
    "#!pip install onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instala skl2onnx import onnxmltools\n",
    "#!pip install skl2onnx\n",
    "#!pip install onnxmltools\n",
    "\n",
    "import onnxmltools\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "import numpy as np\n",
    "\n",
    "from joblib import dump, load\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Cargar el modelo de scikit-learn desde el archivo\n",
    "clf = joblib.load('/workspaces/codespaces-blank/modelos/model_lr.joblib')\n",
    "\n",
    "# Convertir el modelo a ONNX\n",
    "initial_type = [('float_input', FloatTensorType([None, 10]))]\n",
    "onnx_model = onnxmltools.convert_sklearn(clf, initial_types=initial_type)\n",
    "\n",
    "# Guardar el modelo ONNX en un archivo\n",
    "with open('model_lr.onnx', 'wb') as f:\n",
    "    f.write(onnx_model.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingShapeCalculator",
     "evalue": "Unable to find a shape calculator for type '<class 'xgboost.sklearn.XGBRegressor'>'.\nIt usually means the pipeline being converted contains a\ntransformer or a predictor with no corresponding converter\nimplemented in sklearn-onnx. If the converted is implemented\nin another library, you need to register\nthe converted so that it can be used by sklearn-onnx (function\nupdate_registered_converter). If the model is not yet covered\nby sklearn-onnx, you may raise an issue to\nhttps://github.com/onnx/sklearn-onnx/issues\nto get the converter implemented or even contribute to the\nproject. If the model is a custom model, a new converter must\nbe implemented. Examples can be found in the gallery.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingShapeCalculator\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Convertir el modelo a ONNX\u001b[39;00m\n\u001b[1;32m      5\u001b[0m initial_type \u001b[39m=\u001b[39m [(\u001b[39m'\u001b[39m\u001b[39mfloat_input\u001b[39m\u001b[39m'\u001b[39m, FloatTensorType([\u001b[39mNone\u001b[39;00m, \u001b[39m10\u001b[39m]))]\n\u001b[0;32m----> 6\u001b[0m onnx_model \u001b[39m=\u001b[39m onnxmltools\u001b[39m.\u001b[39;49mconvert_sklearn(clf, initial_types\u001b[39m=\u001b[39;49minitial_type)\n\u001b[1;32m      8\u001b[0m \u001b[39m# Guardar el modelo ONNX en un archivo\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmodel_xgb.onnx\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/onnxmltools/convert/main.py:153\u001b[0m, in \u001b[0;36mconvert_sklearn\u001b[0;34m(model, name, initial_types, doc_string, target_opset, targeted_onnx, custom_conversion_functions, custom_shape_calculators)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mskl2onnx is not installed. Please install skl2onnx to use this feature.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    152\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskl2onnx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconvert\u001b[39;00m \u001b[39mimport\u001b[39;00m convert_sklearn \u001b[39mas\u001b[39;00m convert_skl2onnx\n\u001b[0;32m--> 153\u001b[0m \u001b[39mreturn\u001b[39;00m convert_skl2onnx(model, name, initial_types, doc_string, target_opset,\n\u001b[1;32m    154\u001b[0m                         custom_conversion_functions, custom_shape_calculators)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/skl2onnx/convert.py:184\u001b[0m, in \u001b[0;36mconvert_sklearn\u001b[0;34m(model, name, initial_types, doc_string, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, intermediate, white_op, black_op, final_types, dtype, naming, verbose)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    183\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[convert_sklearn] convert_topology\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 184\u001b[0m onnx_model \u001b[39m=\u001b[39m convert_topology(\n\u001b[1;32m    185\u001b[0m     topology, name, doc_string, target_opset, options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    186\u001b[0m     remove_identity\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m intermediate, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    187\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    188\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[convert_sklearn] end\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/skl2onnx/common/_topology.py:1421\u001b[0m, in \u001b[0;36mconvert_topology\u001b[0;34m(topology, model_name, doc_string, target_opset, channel_first_inputs, options, remove_identity, verbose)\u001b[0m\n\u001b[1;32m   1412\u001b[0m container \u001b[39m=\u001b[39m ModelComponentContainer(\n\u001b[1;32m   1413\u001b[0m     target_opset, options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m   1414\u001b[0m     registered_models\u001b[39m=\u001b[39mtopology\u001b[39m.\u001b[39mregistered_models,\n\u001b[1;32m   1415\u001b[0m     white_op\u001b[39m=\u001b[39mtopology\u001b[39m.\u001b[39mraw_model\u001b[39m.\u001b[39m_white_op,\n\u001b[1;32m   1416\u001b[0m     black_op\u001b[39m=\u001b[39mtopology\u001b[39m.\u001b[39mraw_model\u001b[39m.\u001b[39m_black_op,\n\u001b[1;32m   1417\u001b[0m     verbose\u001b[39m=\u001b[39mverbose)\n\u001b[1;32m   1419\u001b[0m \u001b[39m# Traverse the graph from roots to leaves\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[39m# This loop could eventually be parallelized.\u001b[39;00m\n\u001b[0;32m-> 1421\u001b[0m topology\u001b[39m.\u001b[39;49mconvert_operators(container\u001b[39m=\u001b[39;49mcontainer, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m   1422\u001b[0m container\u001b[39m.\u001b[39mensure_topological_order()\n\u001b[1;32m   1424\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(container\u001b[39m.\u001b[39minputs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/skl2onnx/common/_topology.py:1255\u001b[0m, in \u001b[0;36mTopology.convert_operators\u001b[0;34m(self, container, verbose)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[39mfor\u001b[39;00m variable \u001b[39min\u001b[39;00m operator\u001b[39m.\u001b[39moutputs:\n\u001b[1;32m   1253\u001b[0m     _check_variable_out_(variable, operator)\n\u001b[0;32m-> 1255\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_shape_calculator(operator)\n\u001b[1;32m   1256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_converter(operator, container, verbose\u001b[39m=\u001b[39mverbose)\n\u001b[1;32m   1258\u001b[0m \u001b[39m# If an operator contains a sequence of operators,\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[39m# output variables are not necessarily known at this stage.\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/skl2onnx/common/_topology.py:1091\u001b[0m, in \u001b[0;36mTopology.call_shape_calculator\u001b[0;34m(self, operator)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1090\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m'\u001b[39m\u001b[39m[Shape2] call infer_types for \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m, operator)\n\u001b[0;32m-> 1091\u001b[0m     operator\u001b[39m.\u001b[39;49minfer_types()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/skl2onnx/common/_topology.py:589\u001b[0m, in \u001b[0;36mOperator.infer_types\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minfer_types\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    587\u001b[0m     \u001b[39m# Invoke a core inference function\u001b[39;00m\n\u001b[1;32m    588\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m         \u001b[39mraise\u001b[39;00m MissingShapeCalculator(\n\u001b[1;32m    590\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnable to find a shape calculator for type \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    591\u001b[0m                 \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_operator)))\n\u001b[1;32m    592\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    593\u001b[0m         shape_calc \u001b[39m=\u001b[39m _registration\u001b[39m.\u001b[39mget_shape_calculator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype)\n",
      "\u001b[0;31mMissingShapeCalculator\u001b[0m: Unable to find a shape calculator for type '<class 'xgboost.sklearn.XGBRegressor'>'.\nIt usually means the pipeline being converted contains a\ntransformer or a predictor with no corresponding converter\nimplemented in sklearn-onnx. If the converted is implemented\nin another library, you need to register\nthe converted so that it can be used by sklearn-onnx (function\nupdate_registered_converter). If the model is not yet covered\nby sklearn-onnx, you may raise an issue to\nhttps://github.com/onnx/sklearn-onnx/issues\nto get the converter implemented or even contribute to the\nproject. If the model is a custom model, a new converter must\nbe implemented. Examples can be found in the gallery.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar el modelo de scikit-learn desde el archivo\n",
    "clf = joblib.load('/workspaces/codespaces-blank/modelos/model_xgb.joblib')\n",
    "\n",
    "# Convertir el modelo a ONNX\n",
    "initial_type = [('float_input', FloatTensorType([None, 10]))]\n",
    "onnx_model = onnxmltools.convert_sklearn(clf, initial_types=initial_type)\n",
    "\n",
    "# Guardar el modelo ONNX en un archivo\n",
    "with open('model_xgb.onnx', 'wb') as f:\n",
    "    f.write(onnx_model.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.60904498,  0.52768048,  1.64924824, -0.49148502, -1.09841686,\n",
       "        1.06513264,  0.68972086, -0.22262126, -0.0025571 ,  0.14301667])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear una entrada de ejemplo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[370.8086]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "# Crear una sesión ONNX\n",
    "sess = onnxruntime.InferenceSession('model.onnx')\n",
    "\n",
    "# Crear una entrada de prueba\n",
    "X_test = np.array([[5.1, 3.5, 1.4, 0.2]], dtype=np.float32)\n",
    "\n",
    "# Ejecutar el modelo ONNX en la entrada de prueba\n",
    "output = sess.run(None, {'float_input': X_test})\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# Especificar la ubicación del archivo de modelo\n",
    "source_model = '/workspaces/codespaces-blank/modelos/model_xgb.joblib'\n",
    "\n",
    "# Cargar el modelo de Scikit-learn desde el archivo\n",
    "clf = joblib.load(source_model)\n",
    "\n",
    "# Definir el tipo de datos de entrada\n",
    "input_type = [('input', FloatTensorType([None, 10]))]\n",
    "\n",
    "\n",
    "input_type = [('float_input', FloatTensorType([None, 10]))]\n",
    "\n",
    "X = np.array([[1.0, 2.0, 3.0, 4.0,1.0, 2.0, 3.0, 4.0,1.0, 2.0]], dtype=np.float32)\n",
    "\n",
    "# Convertir el modelo a ONNX\n",
    "onnx_model = convert_sklearn(clf, initial_types=input_type, target_opset=11)\n",
    "\n",
    "# Guardar el modelo ONNX en un archivo\n",
    "output_model = '/workspaces/codespaces-blank/modelos/model_xgb.onnx'\n",
    "with open(output_model, 'wb') as f:\n",
    "    f.write(onnx_model.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskl2onnx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_types\u001b[39;00m \u001b[39mimport\u001b[39;00m FloatTensorType\n\u001b[1;32m      6\u001b[0m \u001b[39m# Cargar el modelo de Scikit-learn desde el archivo\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m clf \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mmodel.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      9\u001b[0m \u001b[39m# Definir el tipo de datos de entrada\u001b[39;00m\n\u001b[1;32m     10\u001b[0m input_type \u001b[39m=\u001b[39m [(\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m, FloatTensorType([\u001b[39mNone\u001b[39;00m, \u001b[39m4\u001b[39m]))]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m         obj \u001b[39m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    649\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    651\u001b[0m         \u001b[39mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[39mas\u001b[39;00m fobj:\n\u001b[1;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model.pkl'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# Cargar el modelo de Scikit-learn desde el archivo\n",
    "clf = joblib.load('model.pkl')\n",
    "\n",
    "# Definir el tipo de datos de entrada\n",
    "input_type = [('input', FloatTensorType([None, 4]))]\n",
    "\n",
    "# Crear una entrada de ejemplo\n",
    "X = np.array([[1.0, 2.0, 3.0, 4.0]], dtype=np.float32)\n",
    "\n",
    "# Convertir el modelo a ONNX\n",
    "\n",
    "# Guardar el modelo ONNX en un archivo\n",
    "with open('model.onnx', 'wb') as f:\n",
    "    f.write(onnx_model.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: skl2onnx in /usr/local/python/3.10.4/lib/python3.10/site-packages (1.13)\n",
      "Requirement already satisfied: scikit-learn>=0.19 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from skl2onnx) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/codespace/.local/lib/python3.10/site-packages (from skl2onnx) (1.24.1)\n",
      "Requirement already satisfied: onnx>=1.2.1 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from skl2onnx) (1.13.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/python/3.10.4/lib/python3.10/site-packages (from skl2onnx) (3.20.3)\n",
      "Requirement already satisfied: onnxconverter-common>=1.7.0 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from skl2onnx) (1.13.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/codespace/.local/lib/python3.10/site-packages (from skl2onnx) (1.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/codespace/.local/lib/python3.10/site-packages (from onnx>=1.2.1->skl2onnx) (4.4.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from onnxconverter-common>=1.7.0->skl2onnx) (23.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.19->skl2onnx) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.19->skl2onnx) (3.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade skl2onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
